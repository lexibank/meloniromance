@inproceedings{Meloni2021,
    author = {Meloni, Carlo and Ravfogel, Shauli and Goldberg, Yoav},
    abstract = {Historical linguists have identified regularities in the process of historic sound change. The comparative method utilizes those regularities to reconstruct proto-words based on observed forms in daughter languages. Can this process be efficiently automated? We address the task of proto-word reconstruction, in which the model is exposed to cognates in contemporary daughter languages, and has to predict the proto word in the ancestor language. We provide a novel dataset for this task, encompassing over 8,000 comparative entries, and show that neural sequence models outperform conventional methods applied to this task so far. Error analysis reveals a variability in the ability of neural model to capture different phonological changes, correlating with the complexity of the changes. Analysis of learned embeddings reveals the models learn phonologically meaningful generalizations, corresponding to well-attested phonological shifts documented by historical linguistics.},
    address = {Online},
    booktitle = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
    month = {June},
    pages = {4460--4473},
    publisher = {Association for Computational Linguistics},
    title = {Ab Antiquo: Neural Proto-language Reconstruction},
    url = {https://www.aclweb.org/anthology/2021.naacl-main.353},
    year = {2021}
}
